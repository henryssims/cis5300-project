{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI0LoGHOnl2L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from typing import List, Tuple\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "from score import sari_score\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AkmWnZEnl2L"
      },
      "source": [
        "# Extension 2: Adaptive Decoding Strategy for Real-Time Simplification\n",
        "\n",
        "This extension implements an **adaptive decoding strategy** that optimizes for both quality and latency in real-time text simplification scenarios. The key innovation is using different decoding strategies based on the completion ratio:\n",
        "\n",
        "- **Early stages (25%, 50%)**: Use greedy decoding (num_beams=1) for fast, low-latency generation\n",
        "- **Later stages (75%, 100%)**: Use beam search (num_beams=4) for higher quality when more context is available\n",
        "\n",
        "Additionally, we implement:\n",
        "- **Context-aware length penalty**: Dynamically adjusts based on source length and completion ratio (not just completion ratio like Extension 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JB7RX2gnl2M"
      },
      "outputs": [],
      "source": [
        "def get_sentence_prefix(source: str, completion_ratio: float) -> str:\n",
        "    \"\"\"Extract a prefix of the source sentence based on completion ratio.\"\"\"\n",
        "    tokens = source.split()\n",
        "    num_tokens = len(tokens)\n",
        "    prefix_length = max(1, int(num_tokens * completion_ratio))\n",
        "    prefix_tokens = tokens[:prefix_length]\n",
        "    return ' '.join(prefix_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gYUQbvBnl2M"
      },
      "outputs": [],
      "source": [
        "def compute_context_aware_length_penalty(source: str, completion_ratio: float) -> float:\n",
        "    \"\"\"\n",
        "    Compute length penalty based on source length and completion ratio.\n",
        "\n",
        "    Strategy:\n",
        "    - Shorter sources need less aggressive length penalty\n",
        "    - Early completion ratios benefit from lower length penalty (shorter outputs)\n",
        "    - Later completion ratios can use higher length penalty (more complete outputs)\n",
        "    \"\"\"\n",
        "    source_length = len(source.split())\n",
        "\n",
        "    # Base length penalty increases with completion ratio\n",
        "    base_penalty = 0.4 + (completion_ratio * 0.4)  # Range: 0.4 to 0.8\n",
        "\n",
        "    # Adjust based on source length\n",
        "    if source_length < 10:\n",
        "        length_factor = 0.9  # Shorter sources: slightly lower penalty\n",
        "    elif source_length < 20:\n",
        "        length_factor = 1.0  # Medium sources: no adjustment\n",
        "    else:\n",
        "        length_factor = 1.1  # Longer sources: slightly higher penalty\n",
        "\n",
        "    final_penalty = base_penalty * length_factor\n",
        "\n",
        "    # Clamp to reasonable range\n",
        "    return max(0.3, min(1.0, final_penalty))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7TG4X91nl2M"
      },
      "outputs": [],
      "source": [
        "def adaptive_incremental_simplify(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    source: str,\n",
        "    completion_ratio: float,\n",
        "    max_length: int = 128,\n",
        "    device: str = 'cuda',\n",
        "    measure_latency: bool = False\n",
        ") -> Tuple[str, float]:\n",
        "    \"\"\"\n",
        "    Adaptive incremental simplification with strategy selection based on completion ratio.\n",
        "\n",
        "    Strategy:\n",
        "    - Early completion (25%, 50%): Greedy decoding for low latency\n",
        "    - Late completion (75%, 100%): Beam search for higher quality\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (simplified_text, latency_in_seconds)\n",
        "    \"\"\"\n",
        "    prefix = get_sentence_prefix(source, completion_ratio)\n",
        "\n",
        "    # Adaptive decoding strategy\n",
        "    if completion_ratio <= 0.5:\n",
        "        # Early stage: use greedy decoding (num_beams=1) for maximum speed\n",
        "        # This is much faster than beam search while still producing reasonable quality\n",
        "        num_beams = 1\n",
        "        do_sample = False  # True greedy decoding for maximum speed\n",
        "    else:\n",
        "        # Late stage: use beam search for quality when more context is available\n",
        "        num_beams = 4\n",
        "        do_sample = False\n",
        "\n",
        "    # Context-aware length penalty\n",
        "    length_penalty = compute_context_aware_length_penalty(source, completion_ratio)\n",
        "\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_text = \"simplify: \" + prefix\n",
        "        input_enc = tokenizer(\n",
        "            input_text,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        ).to(device)\n",
        "\n",
        "        generation_kwargs = {\n",
        "            'input_ids': input_enc['input_ids'],\n",
        "            'attention_mask': input_enc['attention_mask'],\n",
        "            'max_length': max_length,\n",
        "            'length_penalty': length_penalty,\n",
        "            'early_stopping': True,\n",
        "            'no_repeat_ngram_size': 2,\n",
        "            'num_beams': num_beams,\n",
        "            'do_sample': do_sample,\n",
        "        }\n",
        "\n",
        "        output_ids = model.generate(**generation_kwargs)\n",
        "        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    latency = time.time() - start_time if measure_latency else 0.0\n",
        "\n",
        "    return output_text, latency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT69QLxenl2N",
        "outputId": "e4f59ac9-2083-4b58-beb4-d8c082015c24"
      },
      "outputs": [],
      "source": [
        "# Load model and data\n",
        "model_dir = './t5-simplification'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "max_length = 128\n",
        "\n",
        "print(\"Loading fine-tuned T5 model...\")\n",
        "if not os.path.exists(model_dir):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Model directory {model_dir} not found. \"\n",
        "        \"Please run strong_baseline.py first to train the model.\"\n",
        "    )\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir, local_files_only=True)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_dir, local_files_only=True)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "print(\"Loading WikiLarge test dataset...\")\n",
        "test = pd.read_csv(\n",
        "    \"hf://datasets/bogdancazan/wikilarge-text-simplification/wiki.full.aner.ori.test.95.tsv\",\n",
        "    sep=\"\\t\"\n",
        ")\n",
        "print(f\"Loaded {len(test)} test examples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY9VMEXpnl2N",
        "outputId": "28ea4831-18b9-4739-abe3-f3f77ec3ca67"
      },
      "outputs": [],
      "source": [
        "# Evaluate Extension 2: Adaptive Decoding Strategy\n",
        "completion_ratios = [0.25, 0.5, 0.75, 1.0]\n",
        "\n",
        "print(\"\\nEvaluating Extension 2: Adaptive Decoding Strategy...\")\n",
        "extension2_results = {ratio: {\n",
        "    'sari': [],\n",
        "    'keep': [],\n",
        "    'delete': [],\n",
        "    'add': [],\n",
        "    'latency': []\n",
        "} for ratio in completion_ratios}\n",
        "\n",
        "for idx, row in tqdm(test.iterrows(), total=len(test), desc=\"Processing\"):\n",
        "    source = row['Normal']\n",
        "    reference = row['Simple']\n",
        "\n",
        "    for ratio in completion_ratios:\n",
        "        output, latency = adaptive_incremental_simplify(\n",
        "            model, tokenizer, source, ratio,\n",
        "            max_length=max_length,\n",
        "            device=device,\n",
        "            measure_latency=True\n",
        "        )\n",
        "\n",
        "        sari, components = sari_score(source, output, [reference])\n",
        "        extension2_results[ratio]['sari'].append(sari)\n",
        "        extension2_results[ratio]['keep'].append(components['keep'])\n",
        "        extension2_results[ratio]['delete'].append(components['delete'])\n",
        "        extension2_results[ratio]['add'].append(components['add'])\n",
        "        extension2_results[ratio]['latency'].append(latency)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF3KYrrnnl2N",
        "outputId": "545d53b1-cecd-434a-aedc-c1513617ca62"
      },
      "outputs": [],
      "source": [
        "# For comparison, also evaluate the fixed length penalty baseline (Baseline)\n",
        "def incremental_simplify_baseline(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    source: str,\n",
        "    completion_ratio: float,\n",
        "    max_length: int = 128,\n",
        "    num_beams: int = 4,\n",
        "    length_penalty: float = 0.6,\n",
        "    device: str = 'cuda',\n",
        "    measure_latency: bool = False\n",
        ") -> Tuple[str, float]:\n",
        "    \"\"\"Baseline incremental simplification with fixed parameters.\"\"\"\n",
        "    prefix = get_sentence_prefix(source, completion_ratio)\n",
        "\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_text = \"simplify: \" + prefix\n",
        "        input_enc = tokenizer(\n",
        "            input_text,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        ).to(device)\n",
        "\n",
        "        output_ids = model.generate(\n",
        "            input_ids=input_enc['input_ids'],\n",
        "            attention_mask=input_enc['attention_mask'],\n",
        "            max_length=max_length,\n",
        "            num_beams=num_beams,\n",
        "            length_penalty=length_penalty,\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=2\n",
        "        )\n",
        "\n",
        "        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    latency = time.time() - start_time if measure_latency else 0.0\n",
        "    return output_text, latency\n",
        "\n",
        "# Extension 1: Adaptive length penalty (beam search with adaptive length penalty)\n",
        "def extension1_adaptive_incremental_simplify(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    source: str,\n",
        "    completion_ratio: float,\n",
        "    max_length: int = 128,\n",
        "    num_beams: int = 4,\n",
        "    device: str = 'cuda',\n",
        "    measure_latency: bool = False\n",
        ") -> Tuple[str, float]:\n",
        "    \"\"\"Extension 1: Adaptive length penalty based on completion ratio.\"\"\"\n",
        "    if completion_ratio <= 0.25:\n",
        "        length_penalty = 0.4\n",
        "    elif completion_ratio <= 0.5:\n",
        "        length_penalty = 0.5\n",
        "    elif completion_ratio <= 0.75:\n",
        "        length_penalty = 0.6\n",
        "    else:\n",
        "        length_penalty = 0.7\n",
        "\n",
        "    return incremental_simplify_baseline(\n",
        "        model, tokenizer, source, completion_ratio,\n",
        "        max_length=max_length,\n",
        "        num_beams=num_beams,\n",
        "        length_penalty=length_penalty,\n",
        "        device=device,\n",
        "        measure_latency=measure_latency\n",
        "    )\n",
        "\n",
        "print(\"\\nEvaluating Baseline (fixed length penalty) for comparison...\")\n",
        "baseline_results = {ratio: {\n",
        "    'sari': [],\n",
        "    'keep': [],\n",
        "    'delete': [],\n",
        "    'add': [],\n",
        "    'latency': []\n",
        "} for ratio in completion_ratios}\n",
        "\n",
        "for idx, row in tqdm(test.iterrows(), total=len(test), desc=\"Processing baseline\"):\n",
        "    source = row['Normal']\n",
        "    reference = row['Simple']\n",
        "\n",
        "    for ratio in completion_ratios:\n",
        "        output, latency = incremental_simplify_baseline(\n",
        "            model, tokenizer, source, ratio,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            length_penalty=0.6,\n",
        "            device=device,\n",
        "            measure_latency=True\n",
        "        )\n",
        "\n",
        "        sari, components = sari_score(source, output, [reference])\n",
        "        baseline_results[ratio]['sari'].append(sari)\n",
        "        baseline_results[ratio]['keep'].append(components['keep'])\n",
        "        baseline_results[ratio]['delete'].append(components['delete'])\n",
        "        baseline_results[ratio]['add'].append(components['add'])\n",
        "        baseline_results[ratio]['latency'].append(latency)\n",
        "\n",
        "print(\"\\nEvaluating Extension 1 (adaptive length penalty) for comparison...\")\n",
        "extension1_results = {ratio: {\n",
        "    'sari': [],\n",
        "    'keep': [],\n",
        "    'delete': [],\n",
        "    'add': [],\n",
        "    'latency': []\n",
        "} for ratio in completion_ratios}\n",
        "\n",
        "for idx, row in tqdm(test.iterrows(), total=len(test), desc=\"Processing extension1\"):\n",
        "    source = row['Normal']\n",
        "    reference = row['Simple']\n",
        "\n",
        "    for ratio in completion_ratios:\n",
        "        output, latency = extension1_adaptive_incremental_simplify(\n",
        "            model, tokenizer, source, ratio,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            device=device,\n",
        "            measure_latency=True\n",
        "        )\n",
        "\n",
        "        sari, components = sari_score(source, output, [reference])\n",
        "        extension1_results[ratio]['sari'].append(sari)\n",
        "        extension1_results[ratio]['keep'].append(components['keep'])\n",
        "        extension1_results[ratio]['delete'].append(components['delete'])\n",
        "        extension1_results[ratio]['add'].append(components['add'])\n",
        "        extension1_results[ratio]['latency'].append(latency)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2_zJOLanl2O",
        "outputId": "ff15c732-1684-47b2-85ea-50e2490a4f19"
      },
      "outputs": [],
      "source": [
        "# Print comprehensive comparison of all three approaches\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPREHENSIVE COMPARISON: Baseline vs Extension 1 vs Extension 2\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SARI Scores Comparison\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Completion Ratio':<20} {'Baseline':<15} {'Extension 1':<18} {'Extension 2':<18}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for ratio in completion_ratios:\n",
        "    baseline_sari = np.mean(baseline_results[ratio]['sari'])\n",
        "    ext1_sari = np.mean(extension1_results[ratio]['sari'])\n",
        "    ext2_sari = np.mean(extension2_results[ratio]['sari'])\n",
        "\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {baseline_sari:>8.2f}      {ext1_sari:>11.2f}      {ext2_sari:>11.2f}\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Latency Comparison (ms)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Completion Ratio':<20} {'Baseline':<15} {'Extension 1':<18} {'Extension 2':<18}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for ratio in completion_ratios:\n",
        "    baseline_lat = np.mean(baseline_results[ratio]['latency']) * 1000\n",
        "    ext1_lat = np.mean(extension1_results[ratio]['latency']) * 1000\n",
        "    ext2_lat = np.mean(extension2_results[ratio]['latency']) * 1000\n",
        "\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {baseline_lat:>8.2f}      {ext1_lat:>11.2f}      {ext2_lat:>11.2f}\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Detailed tables for each approach\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Baseline (Fixed Length Penalty) - Detailed Results\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Completion Ratio':<20} {'SARI':<10} {'Keep':<10} {'Delete':<10} {'Add':<10} {'Avg Latency (ms)':<15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for ratio in completion_ratios:\n",
        "    sari_avg = np.mean(baseline_results[ratio]['sari'])\n",
        "    keep_avg = np.mean(baseline_results[ratio]['keep'])\n",
        "    del_avg = np.mean(baseline_results[ratio]['delete'])\n",
        "    add_avg = np.mean(baseline_results[ratio]['add'])\n",
        "    latency_avg = np.mean(baseline_results[ratio]['latency']) * 1000\n",
        "\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {sari_avg:>6.2f}    {keep_avg:>6.2f}    {del_avg:>6.2f}    {add_avg:>6.2f}    {latency_avg:>10.2f}\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Extension 1 (Adaptive Length Penalty) - Detailed Results\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Completion Ratio':<20} {'SARI':<10} {'Keep':<10} {'Delete':<10} {'Add':<10} {'Avg Latency (ms)':<15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for ratio in completion_ratios:\n",
        "    sari_avg = np.mean(extension1_results[ratio]['sari'])\n",
        "    keep_avg = np.mean(extension1_results[ratio]['keep'])\n",
        "    del_avg = np.mean(extension1_results[ratio]['delete'])\n",
        "    add_avg = np.mean(extension1_results[ratio]['add'])\n",
        "    latency_avg = np.mean(extension1_results[ratio]['latency']) * 1000\n",
        "\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {sari_avg:>6.2f}    {keep_avg:>6.2f}    {del_avg:>6.2f}    {add_avg:>6.2f}    {latency_avg:>10.2f}\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Extension 2 (Adaptive Decoding Strategy) - Detailed Results\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Completion Ratio':<20} {'SARI':<10} {'Keep':<10} {'Delete':<10} {'Add':<10} {'Avg Latency (ms)':<15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for ratio in completion_ratios:\n",
        "    sari_avg = np.mean(extension2_results[ratio]['sari'])\n",
        "    keep_avg = np.mean(extension2_results[ratio]['keep'])\n",
        "    del_avg = np.mean(extension2_results[ratio]['delete'])\n",
        "    add_avg = np.mean(extension2_results[ratio]['add'])\n",
        "    latency_avg = np.mean(extension2_results[ratio]['latency']) * 1000\n",
        "\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {sari_avg:>6.2f}    {keep_avg:>6.2f}    {del_avg:>6.2f}    {add_avg:>6.2f}    {latency_avg:>10.2f}\")\n",
        "\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glEuA_5rnl2O",
        "outputId": "c61d8f84-0451-4ff7-ae80-d4a29f101e5f"
      },
      "outputs": [],
      "source": [
        "# Improvement analysis\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Improvement Analysis: Extension 1 and Extension 2 vs Baseline\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Completion Ratio':<20} {'Ext1 vs Base':<18} {'Ext2 vs Base':<18} {'Ext2 vs Ext1':<18}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for ratio in completion_ratios:\n",
        "    baseline_sari = np.mean(baseline_results[ratio]['sari'])\n",
        "    ext1_sari = np.mean(extension1_results[ratio]['sari'])\n",
        "    ext2_sari = np.mean(extension2_results[ratio]['sari'])\n",
        "\n",
        "    ext1_improvement = ext1_sari - baseline_sari\n",
        "    ext2_improvement = ext2_sari - baseline_sari\n",
        "    ext2_vs_ext1 = ext2_sari - ext1_sari\n",
        "\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {ext1_improvement:>+8.2f}      {ext2_improvement:>+8.2f}      {ext2_vs_ext1:>+8.2f}\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate overall improvements\n",
        "baseline_avg = np.mean([np.mean(baseline_results[r]['sari']) for r in completion_ratios])\n",
        "ext1_avg = np.mean([np.mean(extension1_results[r]['sari']) for r in completion_ratios])\n",
        "ext2_avg = np.mean([np.mean(extension2_results[r]['sari']) for r in completion_ratios])\n",
        "\n",
        "print(f\"\\nOverall Average SARI:\")\n",
        "print(f\"  Baseline:     {baseline_avg:.2f}\")\n",
        "print(f\"  Extension 1: {ext1_avg:.2f} ({ext1_avg-baseline_avg:+.2f}, {(ext1_avg-baseline_avg)/baseline_avg*100:+.2f}%)\")\n",
        "print(f\"  Extension 2: {ext2_avg:.2f} ({ext2_avg-baseline_avg:+.2f}, {(ext2_avg-baseline_avg)/baseline_avg*100:+.2f}%)\")\n",
        "print(f\"  Ext2 vs Ext1: {ext2_avg-ext1_avg:+.2f} ({(ext2_avg-ext1_avg)/ext1_avg*100:+.2f}%)\")\n",
        "\n",
        "# Latency improvements\n",
        "baseline_lat_avg = np.mean([np.mean(baseline_results[r]['latency']) for r in completion_ratios]) * 1000\n",
        "ext1_lat_avg = np.mean([np.mean(extension1_results[r]['latency']) for r in completion_ratios]) * 1000\n",
        "ext2_lat_avg = np.mean([np.mean(extension2_results[r]['latency']) for r in completion_ratios]) * 1000\n",
        "\n",
        "print(f\"\\nOverall Average Latency (ms):\")\n",
        "print(f\"  Baseline:     {baseline_lat_avg:.2f}\")\n",
        "print(f\"  Extension 1: {ext1_lat_avg:.2f} ({ext1_lat_avg-baseline_lat_avg:+.2f} ms)\")\n",
        "print(f\"  Extension 2: {ext2_lat_avg:.2f} ({ext2_lat_avg-baseline_lat_avg:+.2f} ms, {(baseline_lat_avg/ext2_lat_avg):.2f}x speedup)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSH-1IF7nl2O",
        "outputId": "9c6cf1a2-58dc-4745-ca53-2785bce3733f"
      },
      "outputs": [],
      "source": [
        "# Detailed latency analysis for all approaches\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Detailed Latency Analysis\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nBaseline Latency:\")\n",
        "print(f\"{'Completion Ratio':<20} {'Avg (ms)':<15} {'Std Dev (ms)':<15} {'Min (ms)':<15} {'Max (ms)':<15}\")\n",
        "print(\"-\" * 80)\n",
        "for ratio in completion_ratios:\n",
        "    latencies = baseline_results[ratio]['latency']\n",
        "    avg_latency = np.mean(latencies) * 1000\n",
        "    std_latency = np.std(latencies) * 1000\n",
        "    min_latency = np.min(latencies) * 1000\n",
        "    max_latency = np.max(latencies) * 1000\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {avg_latency:>8.2f}      {std_latency:>8.2f}      {min_latency:>8.2f}      {max_latency:>8.2f}\")\n",
        "\n",
        "print(\"\\nExtension 1 Latency:\")\n",
        "print(f\"{'Completion Ratio':<20} {'Avg (ms)':<15} {'Std Dev (ms)':<15} {'Min (ms)':<15} {'Max (ms)':<15}\")\n",
        "print(\"-\" * 80)\n",
        "for ratio in completion_ratios:\n",
        "    latencies = extension1_results[ratio]['latency']\n",
        "    avg_latency = np.mean(latencies) * 1000\n",
        "    std_latency = np.std(latencies) * 1000\n",
        "    min_latency = np.min(latencies) * 1000\n",
        "    max_latency = np.max(latencies) * 1000\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {avg_latency:>8.2f}      {std_latency:>8.2f}      {min_latency:>8.2f}      {max_latency:>8.2f}\")\n",
        "\n",
        "print(\"\\nExtension 2 Latency:\")\n",
        "print(f\"{'Completion Ratio':<20} {'Avg (ms)':<15} {'Std Dev (ms)':<15} {'Min (ms)':<15} {'Max (ms)':<15}\")\n",
        "print(\"-\" * 80)\n",
        "for ratio in completion_ratios:\n",
        "    latencies = extension2_results[ratio]['latency']\n",
        "    avg_latency = np.mean(latencies) * 1000\n",
        "    std_latency = np.std(latencies) * 1000\n",
        "    min_latency = np.min(latencies) * 1000\n",
        "    max_latency = np.max(latencies) * 1000\n",
        "    print(f\"{ratio*100:>5.0f}%{'':<14} {avg_latency:>8.2f}      {std_latency:>8.2f}      {min_latency:>8.2f}      {max_latency:>8.2f}\")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Speedup analysis\n",
        "print(\"\\nSpeedup Analysis:\")\n",
        "print(\"  Baseline & Extension 1: Always use beam search (num_beams=4)\")\n",
        "print(\"  Extension 2: Greedy (num_beams=1) for 25%, 50%; Beam search (num_beams=4) for 75%, 100%\")\n",
        "\n",
        "baseline_early = np.mean(baseline_results[0.25]['latency'] + baseline_results[0.5]['latency']) * 1000\n",
        "baseline_late = np.mean(baseline_results[0.75]['latency'] + baseline_results[1.0]['latency']) * 1000\n",
        "ext2_early = np.mean(extension2_results[0.25]['latency'] + extension2_results[0.5]['latency']) * 1000\n",
        "ext2_late = np.mean(extension2_results[0.75]['latency'] + extension2_results[1.0]['latency']) * 1000\n",
        "\n",
        "print(f\"\\n  Baseline average latency:\")\n",
        "print(f\"    Early stages (25% + 50%): {baseline_early:.2f} ms\")\n",
        "print(f\"    Late stages (75% + 100%): {baseline_late:.2f} ms\")\n",
        "print(f\"\\n  Extension 2 average latency:\")\n",
        "print(f\"    Early stages (25% + 50%): {ext2_early:.2f} ms\")\n",
        "print(f\"    Late stages (75% + 100%): {ext2_late:.2f} ms\")\n",
        "print(f\"\\n  Extension 2 speedup over Baseline:\")\n",
        "print(f\"    Early stages: {baseline_early/ext2_early:.2f}x faster\")\n",
        "print(f\"    Late stages: {baseline_late/ext2_late:.2f}x (similar, both use beam search)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiONJa7jnl2O",
        "outputId": "36f846bc-d6d5-4209-ada2-23d72b8f76d4"
      },
      "outputs": [],
      "source": [
        "# Example outputs\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Example: Adaptive Decoding Strategy\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "example_idx = 0\n",
        "source = test.iloc[example_idx]['Normal']\n",
        "reference = test.iloc[example_idx]['Simple']\n",
        "\n",
        "print(f\"\\nSource: {source}\")\n",
        "print(f\"Reference: {reference}\")\n",
        "print(\"\\n\" + \"-\" * 70)\n",
        "\n",
        "for ratio in completion_ratios:\n",
        "    prefix = get_sentence_prefix(source, ratio)\n",
        "    output, latency = adaptive_incremental_simplify(\n",
        "        model, tokenizer, source, ratio,\n",
        "        max_length=max_length,\n",
        "        device=device,\n",
        "        measure_latency=True\n",
        "    )\n",
        "    sari, _ = sari_score(source, output, [reference])\n",
        "\n",
        "    strategy = \"Greedy\" if ratio <= 0.5 else \"Beam Search\"\n",
        "    num_beams = 1 if ratio <= 0.5 else 4\n",
        "\n",
        "    print(f\"\\n[{ratio*100:.0f}% context] - {strategy} (beams={num_beams})\")\n",
        "    print(f\"  Prefix: {prefix}\")\n",
        "    print(f\"  Output: {output}\")\n",
        "    print(f\"  SARI: {sari:.2f}, Latency: {latency*1000:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z8S_h0IMnl2P",
        "outputId": "218f86b0-dac4-4cc6-8dbc-a5c576dc7019"
      },
      "outputs": [],
      "source": [
        "# Create plots for SARI scores\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: SARI Scores\n",
        "ratios = [r*100 for r in completion_ratios]\n",
        "baseline_saris = [np.mean(baseline_results[r]['sari']) for r in completion_ratios]\n",
        "ext1_saris = [np.mean(extension1_results[r]['sari']) for r in completion_ratios]\n",
        "ext2_saris = [np.mean(extension2_results[r]['sari']) for r in completion_ratios]\n",
        "\n",
        "ax1.plot(ratios, baseline_saris, marker='o', label='Baseline (Fixed Length Penalty)', linewidth=2, markersize=8)\n",
        "ax1.plot(ratios, ext1_saris, marker='s', label='Extension 1 (Adaptive Length Penalty)', linewidth=2, markersize=8)\n",
        "ax1.plot(ratios, ext2_saris, marker='^', label='Extension 2 (Adaptive Decoding)', linewidth=2, markersize=8)\n",
        "ax1.set_xlabel('Completion Ratio (%)', fontsize=12)\n",
        "ax1.set_ylabel('SARI Score', fontsize=12)\n",
        "ax1.set_title('SARI Scores Across Completion Ratios', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(ratios)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.set_ylim([25, 38])\n",
        "\n",
        "# Plot 2: Latency\n",
        "baseline_lats = [np.mean(baseline_results[r]['latency']) * 1000 for r in completion_ratios]\n",
        "ext1_lats = [np.mean(extension1_results[r]['latency']) * 1000 for r in completion_ratios]\n",
        "ext2_lats = [np.mean(extension2_results[r]['latency']) * 1000 for r in completion_ratios]\n",
        "\n",
        "ax2.plot(ratios, baseline_lats, marker='o', label='Baseline (Fixed Length Penalty)', linewidth=2, markersize=8)\n",
        "ax2.plot(ratios, ext1_lats, marker='s', label='Extension 1 (Adaptive Length Penalty)', linewidth=2, markersize=8)\n",
        "ax2.plot(ratios, ext2_lats, marker='^', label='Extension 2 (Adaptive Decoding)', linewidth=2, markersize=8)\n",
        "ax2.set_xlabel('Completion Ratio (%)', fontsize=12)\n",
        "ax2.set_ylabel('Average Latency (ms)', fontsize=12)\n",
        "ax2.set_title('Latency Across Completion Ratios', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(ratios)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.set_yscale('log')  # Log scale for better visualization\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create bar chart comparison\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Bar chart for SARI\n",
        "x = np.arange(len(ratios))\n",
        "width = 0.25\n",
        "\n",
        "ax1.bar(x - width, baseline_saris, width, label='Baseline', alpha=0.8)\n",
        "ax1.bar(x, ext1_saris, width, label='Extension 1', alpha=0.8)\n",
        "ax1.bar(x + width, ext2_saris, width, label='Extension 2', alpha=0.8)\n",
        "ax1.set_xlabel('Completion Ratio (%)', fontsize=12)\n",
        "ax1.set_ylabel('SARI Score', fontsize=12)\n",
        "ax1.set_title('SARI Scores Comparison (Bar Chart)', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(ratios)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "ax1.set_ylim([25, 38])\n",
        "\n",
        "# Bar chart for Latency\n",
        "ax2.bar(x - width, baseline_lats, width, label='Baseline', alpha=0.8)\n",
        "ax2.bar(x, ext1_lats, width, label='Extension 1', alpha=0.8)\n",
        "ax2.bar(x + width, ext2_lats, width, label='Extension 2', alpha=0.8)\n",
        "ax2.set_xlabel('Completion Ratio (%)', fontsize=12)\n",
        "ax2.set_ylabel('Average Latency (ms)', fontsize=12)\n",
        "ax2.set_title('Latency Comparison (Bar Chart)', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(ratios)\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "ax2.set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56WsX4sNnl2P",
        "outputId": "5efbd3b8-6b4a-4736-b55b-842e6c9d0a2e"
      },
      "outputs": [],
      "source": [
        "# Detailed breakdown by component for all three approaches\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Component-wise Analysis: Baseline vs Extension 1 vs Extension 2\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "components = ['keep', 'delete', 'add']\n",
        "for comp in components:\n",
        "    print(f\"\\n{comp.upper()} Component:\")\n",
        "    print(f\"{'Completion Ratio':<20} {'Baseline':<15} {'Extension 1':<18} {'Extension 2':<18}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for ratio in completion_ratios:\n",
        "        baseline_val = np.mean(baseline_results[ratio][comp])\n",
        "        ext1_val = np.mean(extension1_results[ratio][comp])\n",
        "        ext2_val = np.mean(extension2_results[ratio][comp])\n",
        "\n",
        "        print(f\"{ratio*100:>5.0f}%{'':<14} {baseline_val:>8.2f}      {ext1_val:>11.2f}      {ext2_val:>11.2f}\")\n",
        "\n",
        "    baseline_avg = np.mean([np.mean(baseline_results[r][comp]) for r in completion_ratios])\n",
        "    ext1_avg = np.mean([np.mean(extension1_results[r][comp]) for r in completion_ratios])\n",
        "    ext2_avg = np.mean([np.mean(extension2_results[r][comp]) for r in completion_ratios])\n",
        "\n",
        "    print(f\"{'Average':<20} {baseline_avg:>8.2f}      {ext1_avg:>11.2f}      {ext2_avg:>11.2f}\")\n",
        "    print(f\"{'Ext1 vs Base':<20} {ext1_avg-baseline_avg:>+8.2f}      {'':<11}\")\n",
        "    print(f\"{'Ext2 vs Base':<20} {ext2_avg-baseline_avg:>+8.2f}      {'':<11}\")\n",
        "    print(f\"{'Ext2 vs Ext1':<20} {ext2_avg-ext1_avg:>+8.2f}      {'':<11}\")\n",
        "\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt2jgtNFnl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67T2sFuinl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5m_ebkKnl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTh7JUFFnl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atD70W52nl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08SK7WQ2nl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRELLn7Onl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHPYY5fynl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AisRonvtnl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QVPwi1dnl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjO0NQy2nl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaHWeapNnl2P"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZu-FPl0nl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FY3zeIhvnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoEGp1OKnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXq6IvvLnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM6hNueSnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTaAedpcnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMWsXfDQnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddvzourZnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fqPDiVPnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAvkSrpEnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy9OyWLUnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG7-c9YAnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37S_eqYjnl2Q"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
